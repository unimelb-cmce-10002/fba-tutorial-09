<!-- question-type: prepare -->
### Exercise 4: First Steps with K-Means Clustering

You've prepared a numeric dataset of employee features — now let’s try to find **natural groupings** among employees using **K-means clustering**.

**(a)** What do you think K-means clustering tries to do?  
Try to explain it in your own words — no need to be technical yet.  

*Hint: Think about what it means for observations to be “similar” and how K-means might group them.*

**(b)** Complete the code below to run K-means clustering on your `df_scaled` data, asking for 3 clusters.  
We've asked the function to use 10 random starting points (`nstart = 10`) to improve stability, and set a seed for reproducibility.

```{r}
#| eval: false
set.seed(123)  

kmeans_model <- 
    YOUR_CODE(YOUR_DATA, 
           centers = YOUR_NUMBER, 
           nstart = 10
           )
```

**(c)** Complete the code below to visualise the clusters.

```{r}
#| eval: false
fviz_cluster(
  YOUR_MODEL,
  data = YOUR_DATA,
  palette = c("#00AFBB", "#2E9FDF", "#E7B800"),
  ggtheme = theme_minimal(),
  main = "K-means Clustering Results"
)
```

**(d)** Interpret the plot.
Do the clusters look well-separated? 

**(e)** Which variables might be driving the clustering? Complete the code below.

```{r}
#| eval: false
# include variables we want to keep from our analysis and attrition
df_clustered <- 
    df |> 
    select(YOUR_VARIABLES)

# add the cluster assignment to the data
df_clustered <- 
    augment(kmeans_model, df_clustered)

# Now some summary statistics grouping by cluster
df_clustered |>
    group_by(YOUR_VARIABLE) |>
    summarise(across(job_satisfaction:age, mean))

df_clustered |>
    group_by(YOUR_VARIABLE) |>
    summarise(
        count = n(),
        attrition_rate = mean(attrition == "Yes")
    )
```


<!-- BEGIN PROFILE:r-teaching-guide -->
::: {.content-visible when-profile="r-teaching-guide"}

::: {.teaching-block}

::: {.teaching-block-header}
Teaching Note
:::

::: {.teaching-block-body}

🎯 **Learning Objective** 
Students should:

- Understand the basic intuition behind K-means clustering.
- Apply K-means clustering in R using pre-processed data.
- Visualize and interpret cluster output.
- Relate cluster membership back to original business features, including attrition.

✅   **Core Concepts to Highlight**


- K-means mechanics: Iterative partitioning based on distance to centroids.
- Why set a seed: Ensures reproducibility due to randomness in initialization.
- Cluster interpretation: Use group means and visualizations to infer meaning.
- Link to business: Clusters may indicate meaningful employee profiles (e.g. high attrition vs. low attrition groups).


💬 **Suggested In-Class Prompts** (if needed)

“What would make two employees ‘similar’ in this dataset?”

“What’s a potential risk of clustering without scaling?”

“Why might the clusters not be cleanly separated?”

“Does clustering explain attrition, or just reveal patterns?”

📌 **Common Misunderstandings**

- Assuming clustering is prediction: Students may confuse clustering with supervised learning.
- Overinterpreting clusters: Clusters may not map cleanly onto real-world categories.
- Believing K-means is deterministic: It’s not — hence the need for `set.seed()` and `nstart`.

:::

:::

:::
<!-- END PROFILE:r-teaching-guide -->

<!-- BEGIN PROFILE:r-solutions -->
::: {.content-visible when-profile="r-solutions" when-profile="r-teaching-guide"}

::: {.solution-block}

::: {.solution-block-header}
Solution
:::

::: {.solution-block-body}

**(a)**

K-means clustering groups observations into K clusters such that observations within the same cluster are more similar to each other than to those in other clusters. It does this by:

* Randomly assigning K cluster centers,
* Assigning each observation to the nearest cluster center,
* Recalculating cluster centers as the mean of assigned points,
* Repeating until assignments stabilize.

It's an unsupervised learning method that tries to find natural groupings in data.

**(b)**
```{r}
set.seed(123)  # ✅ ensures reproducibility
kmeans_model <- kmeans(df_scaled, centers = 3, nstart = 10)
```

**(c)**
```{r}
fviz_cluster(
  kmeans_model,
  data = df_scaled,
  palette = c("#00AFBB", "#2E9FDF", "#E7B800"),
  ggtheme = theme_minimal(),
  main = "K-means Clustering Results"
)
```
**(d)**
Cluster 2 looks well separated, lots of overlap between clusters 1 and 3.

**(e)**

Cluster 1 and 3 similar except for avg job satisfaction.

```{r}
# Some example code. No means the best.
df_clustered <- 
  df |> 
  select(job_satisfaction, monthly_income, years_at_company, distance_from_home, age, attrition)

df_clustered <- augment(kmeans_model, df_clustered)

df_clustered |>
    group_by(.cluster) |>
    summarise(across(job_satisfaction:age, mean))

df_clustered |>
    group_by(.cluster) |>
    summarise(
        count = n(),
        attrition_rate = mean(attrition == "Yes")
    )
```


:::

:::

:::
<!-- END PROFILE:r-solutions -->