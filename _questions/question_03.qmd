<!-- question-type: prepare -->
### Exercise 3: Preparing Data for Clustering

You've been asked to explore whether there are natural groupings of employees based on key workplace characteristics. 
Clustering sounds like a promising direction ‚Äî but before you dive in, your colleague suggests you first prepare a clean, numeric dataset.

They recommend using the following variables:

- `job_satisfaction`  
- `monthly_income`  
- `years_at_company`  
- `distance_from_home`  
- `age`

**(a)** Why might your colleague suggest using only numeric variables at this stage?  

*Hint: Think about how clustering methods like K-means work.*

**(b)** Why is it important to scale or normalise the variables before clustering?

**(c)** Complete the  preprocessing pipeline below that:

- selects the 5 numeric variables above  
- scales (normalises) them so they are all on the same scale (mean 0, SD 1)

```{r}
#| eval: false
rec <- 
    YOUR_CODE(~ ., data = df |> 
        YOUR_CODE(job_satisfaction, monthly_income, years_at_company, distance_from_home, age)
        ) |>
    YOUR_CODE (all_numeric_predictors())

df_scaled <- 
    YOUR_CODE(rec) |> 
    YOUR_CODE(new_data = NULL)
```

**(d)** Check that your preprocessing worked by printing the mean and standard deviation of each column in `df_scaled`. What do you notice?

<!-- BEGIN PROFILE:r-teaching-guide -->
::: {.content-visible when-profile="r-teaching-guide"}

::: {.teaching-block}

::: {.teaching-block-header}
Teaching Note
:::

::: {.teaching-block-body}

üéØ **Learning Objective** 
Students should:

- Understand the importance of scaling numeric variables before clustering.
- Identify why only numeric inputs are suitable for K-means.
- Implement a basic preprocessing pipeline using recipes.
- Check whether scaling was successful using summary statistics.

‚úÖ   **Core Concepts to Highlight**

- Why K-means requires numeric data: because it uses distance (e.g. Euclidean) as a basis for forming clusters.
- Importance of scaling: variables with larger scales dominate unscaled clustering.
- What scaling does: standardizes variables to mean 0 and SD 1.
- How recipes workflows are constructed: defining, prepping, baking.
- Interpreting results: using summary statistics (mean/SD) to verify scaling.


üí¨ **Suggested In-Class Prompts** (if needed)

‚ÄúWhat would happen if we included income without scaling, but left satisfaction untouched?‚Äù

üìå **Common Misunderstandings**

- Not understanding the three-step recipes flow (recipe(), prep(), bake()).
- Forgetting to assign the baked output to a new object.
- Expecting all columns to remain in the output ‚Äî rather than just the selected ones.

:::

:::

:::
<!-- END PROFILE:r-teaching-guide -->

<!-- BEGIN PROFILE:r-solutions -->
::: {.content-visible when-profile="r-solutions" when-profile="r-teaching-guide"}

::: {.solution-block}

::: {.solution-block-header}
Solution
:::

::: {.solution-block-body}

**(a)** Why might your colleague suggest using only numeric variables?

Clustering methods like K-means rely on calculating distances between observations (e.g., Euclidean distance). These methods require numeric inputs, as categorical variables do not have a natural ordering or spacing and can't be meaningfully included (without transformation).

**(b)** Why is it important to scale or normalise the variables?

If variables are not scaled, those with larger ranges (e.g., income in thousands) will dominate the distance calculations, while variables with smaller scales (e.g., satisfaction scores out of 4) will have minimal impact. Scaling ensures each variable contributes equally to the clustering.

**(c)** Preprocessing pipeline to normalise the variables

```{r}
#| eval: true
rec <- 
    recipe(~ ., data = df |> 
        select(job_satisfaction, monthly_income, years_at_company, distance_from_home, age)
        ) |>
    step_normalize(all_numeric_predictors())

df_scaled <- 
    prep(rec) |> 
    bake(new_data = NULL)
```

**(d)**

```{r}
# a shortcut to manually writing every command.
# you may prefer the manual way (see commented out code below)
df_scaled |>
  pivot_longer(everything(), names_to = "variable") |>
  group_by(variable) |>
  summarise(mean = mean(value), sd = sd(value))

# df_scaled |> 
#   summarise(
#     mean_job_satisfaction = mean(job_satisfaction),
#     sd_job_satisfaction = sd(job_satisfaction),
#     
#     mean_monthly_income = mean(monthly_income),
#     sd_monthly_income = sd(monthly_income),
#     
#     mean_years_at_company = mean(years_at_company),
#     sd_years_at_company = sd(years_at_company),
#     
#     mean_distance_from_home = mean(distance_from_home),
#     sd_distance_from_home = sd(distance_from_home),
#     
#     mean_age = mean(age),
#     sd_age = sd(age)
#   )

```

:::

:::

:::
<!-- END PROFILE:r-solutions -->